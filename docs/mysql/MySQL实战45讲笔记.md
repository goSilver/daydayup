### 01 基础架构：一条SQL查询语句是如何执行的？
- 客户端 -> 连接器 -> 查询缓存 -> 分析器 -> 优化器 -> 执行器 -> 存储引擎
   - **连接器**
      - 负责跟客户端建立连接、获取权限、维持和管理连接
      - 客户端如果太长时间（默认8h）没动静，连接器就会自动将它断开
      - 长连接：是指客户端如果持续有请求，则一直使用同一个连接
         - 过多会占用内存而OOM
            - 定期断开长连接
            - 执行mysql_reset_connection来重新初始化连接资源
      - 短连接：是指每次请求完后就断开连接，下次请求再建立一个
   - 查询缓存
      - 缓存失效非常频繁
      - 8.0以后整个查询缓存模块删除了
   - **分析器**
      - 词法分析：识别sql字符串里分别是什么、代表什么
      - 语法分析：根据语法规则，判断sql语句是否复合MySQL语法
   - **优化器**
      - 决定用哪个索引
      - 决定各个表的join顺序
   - **执行器**
      - 开始执行前，判断用户是否对整个表T是否有对应的操作权限
      - 调用存储引擎对应的读写接口进行数据读写
### 02 日志系统：一条SQL更新语句是如何执行的？

1. 问题：如果每次更新操作都要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程的**IO成本**、**查找成本**都非常高。
1. WAL技术：Write-Ahead Logging，**先写日志，再写磁盘**。当有一条记录需要更新时，InnoDB引擎就会**先把记录写到redo log里，并更新内存，这个时候更新就算完成了。**
1. redo log（重做日志）和binlog（归档日志）
   1. InnoDB的redo log是**固定大小**的。从头开始写，写到末尾就又回到开头**循环写**。
   1. 有了redo log，InnoDB就可以保证即使数据库发生**异常重启**，之前提交的记录都不会丢失，这个 能力称为**crash-safe**。
4. 为什么要有两份日志？
   1. 只依靠binlog是没有crash-safe能力的，所以InnoDB使用redo log来实现crash-safe能力。
5. 这两种日志有以下三点不同
   1. redo log是**InnoDB引擎特有**的；binlog是MySQL的**Server层**实现的，所有引擎都可以使用。 
   1. 日志格式
      1. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；
      1. binlog是逻辑日志，记录的 是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
   3. redo log是**循环写**的，空间固定会用完；binlog是可以**追加写**入的。
6. redo log和binlog依靠什么机制保持一致性？
   1. **两阶段提交**。先写redo log并标记为**prepare**状态，再写binlog刷盘，提交事务并将redo log的状态标记为**commit**。
### 03 事务隔离：为什么你改了我还看不见？

1. **InnoDB支持事务，而MyISAM不支持。**
1. 隔离性与隔离级别
   1. 隔离性：ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一 致性、隔离性、持久性）
   1. 隔离级别：读未提交、读已提交、可重复读、串行化
   1. 在实现上，数据库里面会创建一个视图（**快照**），访问的时候以视图的逻辑结果为准。
      1. 可重复读：这个视图是在**事务启动时**创建的，整个事务存在期间都用这个视图；
      1. 读已提交：这个视图是在**每个SQL语句开始执行**的时候创建的；
      1. 读未提交：**直接返回记录上的最新值**，没有视图概念；
      1. 串行化：直接用**读加读锁**、**写加写锁**的方式来避免并行访问。
3. 尽量不要使用长事务
   1. **长事务**意味着系统里面会存在很老的事务视图。
      1. 由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交**之前**，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
   2. 除了回滚段的影响，长事务还**占用锁资源**。
4. 事务的启动方式
   1. **显式启动**事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是 rollback。
   1. **set autocommit = 0**，这个命令会将这个线程的自动提交**关掉**。意味着如果你只执行一个 select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
### 04 深入浅出索引（上）

1. 索引的常见模型
   1. **哈希表**：一种以键-值（key-value）存储数据的结构
      1. 优点：等值查询快；插入快；
      1. 缺点：**范围查询性能差**；
   2. **有序数组**
      1. 优点：等值查询、范围查询性能优秀；
      1. 缺点：在**中间插入**一条数据的代价太高；
   3. **搜索树**
      1. 平衡二叉树：为了维持BST，读写的时间复杂度都是**O(logN)**。缺点，**IO次数太多**。
      1. **B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数**。
      1. 为什么不用B树或者红黑树？
         1. B树
            1. B树非叶子节点也存数据，导致单个节点能存的数据量更少，树高更高，磁盘IO更多
         2. 红黑树
            1. **树的深度过大**而造成磁盘IO读写过于频繁
2. InnoDB 的索引模型
   1. 根据**叶子节点**的内容，索引类型分为主键索引和非主键索引
      1. **主键索引**的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为**聚簇索引**（clustered index）。
      1. **非主键索引**的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为**二级索引**（secondary index）。
   2. 先查一遍二级索引，再回到主键索引树搜索，这个过程称为**回表**。
3. 索引维护
   1. B+树为了维护索引**有序性**，在插入新值的时候需要做必要的维护。
      1. 页分裂
      1. 页合并
   2. **为什么一定要定义自增主键？**
      1. 自增主键的插入数据模式，正符合了我们前面提到的**递增插入**的场景。每次插入一条新记录，都是**追加**操作，都**不涉及到挪动**其他记录，也**不会触发叶子节点的分裂**。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样**写**数据成本相对较高。
      1. 主键**长度越小**，普通索引的叶子节点就越小，普通索引占用的**空间**也就**越小**。
      1.  所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。
### 05 深入浅出索引（下）

1. **回表**：回到主键索引树搜索的过程，称之为回表。
1. **覆盖索引**
   1. 在一个查询里面，索引K已经“覆盖了”我们的查询需求，我们称之为“**覆盖索引**”。
   1. 由于覆盖索引可以**减少树的搜索次数（少一次回表）**，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
3. **最左前缀原则**
   1. B+树这种索引结构，可以利用索引的**“最左前缀”**，来定位记录。
4. 在建立联合索引的时候，如何安排索引内的字段顺序？
   1. 评估标准是，**索引的复用能力**
      1. 第一原则是，如果通过调整顺序，可 以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的
      1. 第二原则是，索引怎么建更**节约磁盘空间**
5. **索引下推**
   1. MySQL 5.6 引入的**索引下推**优化（index condition pushdown)， 可以在索引遍历过程中，**对索引中包含的字段先做判断**，直接**过滤**掉不满足条件的记录，**减少回表次数**。
6. 补充
   1. **为什么重建索引？**
      1. 索引可能因为删除、页分裂等原因，导致数据也有**空洞**，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率更高，也就是索引更紧凑、更省空间。
   2. 不论是删除主键还是创建主键，都会将整个表重建。
### 06 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

1. **全局锁**：对整个数据库实例加锁
   1. 典型使用场景是，做全库逻辑备份。
2. **表级锁**：
   1. **表锁**：语法是 lock tables …read/write。
   1. **元数据锁**（meta data lock，MDL)：MDL不需要显式使用，在访问一个表的时候会被自动加上。**MDL的作用是，保证读写的正确性**。MySQL 5.5版本中引入了MDL，当对一个表做**增删改查**操作的时候，加**MDL读锁**；当要对表做**结构变更**操作的时候，加**MDL写锁**。**MDL会直到事务提交才释放**，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。
      1. 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
      1. 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。
   3. **如何安全的给小表加字段？**
      1. **解决长事务**，事务不提交，就会一直占着MDL锁。
         1. 缺点：热点数据解决不了。
      2. 在alter table里加**超时时间**，在超时时间内拿到MDL写锁就执行，拿不到也不阻塞后面的业务语句，先放弃。
### 07 行锁功过：怎么减少行锁对性能的影响？

1. **两阶段锁协议**
   1. 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到**事务结束时才释放**。这个就是**两阶段锁协议**。
   1. 结论：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量**往后放**。
2. **死锁和死锁检测**
   1. 当并发系统中不同线程出现**循环资源依赖**，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。
   1. 当出现死锁以后，有两种策略： 
      1. 一种策略是，**直接进入等待**，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。 
      1. 另一种策略是，**发起死锁检测**，发现死锁后，主动**回滚死锁链条**中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。
   3. **怎么解决由这种热点行更新导致的性能问题呢？**
      1. 关闭死锁检测。
         1. 对业务有损，放弃。
      2. 对于相同行的更新， 在进入引擎之前排队。
         1. 要改源码，难度大。
      3. 通过将一行改成逻辑上的多行来减少锁冲突。
         1. 需要根据业务逻辑做详细设计。
### 08 事务到底是隔离的还是不隔离的？

1. **MVCC工作原理**
   1. InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“**活跃**”的所有**事务ID**。**“活跃”指的就是，启动了但还没提交**。数组里面事务ID的最小值记为**低水位**，当前系统里面已经创建过的事务ID的最大值加1记为**高水位**。 **这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。** 而数据版本的可见性规则，就是基于数据的**rowtrx_id**和这个一致性视图的对比结果得到的。 这个视图数组把所有的rowtrx_id 分成了几种不同的情况。

![](https://cdn.nlark.com/yuque/0/2021/png/2548312/1622654182839-a1ef30a6-cf5b-4b74-8d4a-19ad3496fa0a.png#align=left&display=inline&height=180&margin=%5Bobject%20Object%5D&name=&originHeight=359&originWidth=848&size=0&status=done&style=none&width=424)
这样，对于当前事务的启动瞬间来说，一个数据版本的rowtrx_id，有以下几种可能：

   1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是**可见**的；
   1. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定**不可见**的；
   1. 如果落在黄色部分，那就包括两种情况
      1. 若 rowtrx_id**在**数组中，表示这个版本是由还没提交的事务生成的，**不可见**； 
      1. 若 rowtrx_id**不在**数组中，表示这个版本是已经提交了的事务生成的，**可见**。
2. **更新逻辑**
   1. 更新数据都是**先读后写**的，而这个读，只能读当前的值，称为“**当前读**”。
   1. 除了update语句外，select语句如果加锁，也是当前读。
   1. 可重复读的核心逻辑就是**一致性读**；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
### 09 普通索引和唯一索引，应该怎么选择？

1. 查询过程
   1. 对于**普通索引**来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。 
   1. 对于**唯一索引**来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
   1. **引擎是****按页读写****的**，在InnoDB中，每个数据页的大小默认是**16K****B**。
2. 更新过程

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在**change buffer**中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要**访问**这个数据页的时候，将数据页**读入内存**，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 


也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。 **将change buffer中的操作应用到原数据页，得到最新结果的过程称为****merge****。**

- **除了访问这个数据页会触发merge外**
- **系统有后台线程会定期merge**
- **在数据库正常关闭（shutdown）的过程中，也会执行merge操作。**



显然，如果能够将更新操作先记录在change buffer，**减少读磁盘**，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够**避免占用内存**，提高内存利用率。


对于**唯一索引**来说，所有的更新操作都要先判断这个操作是否违反**唯一性约束**。
因此，**唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。**


**如果要在这张表中插入一个 新记录(4,400)的话，InnoDB的处理流程是怎样的?**

- 第一种情况是，这个记录要更新的**目标页在内存中**
   - 唯一索引会判断这个值有没有冲突，如果没有则直接插入；
   - 普通索引直接写入数据页；

这样情况下，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU时间。


- 第二种情况是，这个记录要更新的**目标页不在内存中**
   - 对于唯一索引来说，需要将**数据页读入内存**，判断到没有冲突，插入这个值，语句执行结束；
   - 对于普通索引来说，则是将更新记录在change buffer，语句执行结束；

将数据从磁盘读入内存涉及**随机IO**的访问，是数据库里面成本最高的操作之一。
**change buffer 因为减少了随机磁盘访问**，所以对更新性能的提升是会很明显的。


4. **普通索引的所有场景，使用change buffer都可以起到加速作用吗？**
   1. 在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。
   1. 对于**写多读少**的场景，change buffer能显著提升效率；
   1. 但如果是**写入之后立马就做查询**的场景，会频繁触发merge操作，不但没有减少随机IO次数，反而增加了维护change buffer的开销。
5. **change buffer 和 redo log**
   1. redo log主要节省的是**随机写**磁盘的IO消耗（转成顺序写）
   1. change buffer主要节省的则是**随机读**磁盘的IO消耗。
6. 如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据？
   1. 这个问题的答案是**不会丢失**，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。
### 10 MySQL为什么有时候会选错索引？

1. 使用哪个索引是由MySQL**优化器**来确定的。
1. 使用**force index(a)**来让优化器强制使用索引a。
1. 在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。 当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。
### 11 怎么给字符串字段加索引？

1. MySQL是支持**前缀索引**的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。
```sql
mysql> alter table SUser add index index1(email);
或
mysql> alter table SUser add index index2(email(6));
```

2. **前缀索引**
   1. 优点：**占用的空间会更小**。 
   1. 缺点：可能会**增加额外的记录扫描次数**。
   1. 结论：使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。
3. **前缀索引对覆盖索引的影响**
   1. **使用前缀索引就用不上覆盖索引对查询性能的优化了**
4. 索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。
   1. **倒序存储**
   1. **增加hash字段**
### 12 为什么我的MySQL会“抖”一下？

1. 你的sql语句为什么变“慢”了
   1. InnoDB在处理更新语句的时候，只做了写日志这一个**磁盘写操作**。
   1. 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“**脏页**”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“**干净页**”。
   1. 把内存里的数据写入磁盘的过程，术语就是**flush**。
   1. flush时机
      1. **redo log写满了**
      1. **系统内存不足**
      1. **MySQL认为系统“空闲”的时候**
      1. **MySQL正常关闭的时候**
2. InnoDB刷脏页的控制策略
   1. **innodb_io_capacity**，这个参数告诉InnoDB你的磁盘的IO能力
   1. InnoDB刷盘速度主要参考两个因素：一个是**脏页比例**；一个是**redo log写盘速度**。
   1. “**连坐机制**”，刷自己时把邻居脏页也刷掉，减少随机IO，8.0以后默认关闭
### 13 为什么表数据删掉一半，表文件大小不变？

1. innodb_file_per_table
   1. 表数据既可以存在**共享空间**里，也可以是**单独的文件**。
2. 数据删除流程
   1. **delete**只是把记录的位置，或者数据也标记为“**可复用**”，但磁盘文件大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可复用，而没有被使用的空间，看起来就是“空洞”。
   1. 经过过大量增删改查的表，都是可能存在空洞的。所以，如果能把这些空洞去掉，就能达到**收缩表空间**的目的。
3. 重建表
   1. **alter table A engine = InnoDB**命令来重建表
      1. 缺点：在整个DDL过程中，不能有数据更新
   2. **Online DDL**
   2. 三种重建方式区别
      1. alter table t engine = InnoDB（也就是recreate）默认的就是图四流程
      1. analyze table t其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁
      1. optmize table t等于recreate + analyze
### 14 count(*)这么慢，我该怎么办？

1. **count(*)的实现方式**
   1. MyISAM表虽然count(*)很快，但是不支持事务；
   1. showtable status命令虽然返回很快，但是不准确；
   1. InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。
2. **为什么InnoDB不把行数存起来呢？**
   1. 因为即使是在同一个时刻的多个查询，由于**多版本并发控制（MVCC）**的原因，InnoDB表表示“行数”也是不确定的。
   1. MySQL优化器会找到**最小**那棵树来遍历获取行数
3. **用缓存系统保存计数**
   1. 将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使Redis正常工作，这个值还是逻辑上不精确的。
4. **在数据库保存计数**
   1. 利用“**事务**”这个特性解决
5. **不同的count用法**
   1. count(id)：遍历整张表，把每一行的id取出来，返回给sever层。server层拿到id后，判断不可能是空的，就按行累加。
   1. count(1)：遍历整表，但不取值。server层对于返回的每一个行，放一个数字“1”进去，判断是不可能为空的，按行累加。
   1. count(字段)
      1. 如果这个字段定义是**not null**的话，逐行取，判断不能为null，按行累加
      1. 如果这个字段定义是**允许为null**的话，逐行取，判断**不是null，才累加**
   4. 但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，**不取值**。count(*)肯定不是null，按行累加。
   4. 所以结论是：按照效率排序的话，**count(字段)<count(主键)<count(1)<count(*)**
### 15 答疑文章（一）：日志和索引相关问题

- 见正文
### 16 “order by”是怎么工作的？

1. **全字段排序**
   1. Extra这个字段中的“**Using filesort**”表示的就是需要排序，MySQL会给**每个线程**分配一块**内存**用于排序，称为**sort_buffer**。
   1. **sort_buffer_size**，就是MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用**磁盘临时文件**辅助排序。
   1. 如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成。
2. **rowid排序**
   1. 新的算法放入sort_buffer的字段，**只需要排序的列和主键id。**
3. **全字段排序 VS rowid排序**

如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。 


如果MySQL认为内存足够大，会**优先选择全字段排序**，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。 


这也就体现了MySQL的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。


对于InnoDB表来说，**rowid排序会要求回表多造成磁盘读，因此不会被优先选择。**

4. Extra字段里面如果多了“**Using index**”，表示的就是使用了覆盖索引，性能上会快很多。
### 17 如何正确地显示随机消息？

1. **内存临时表**
   1. Extra字段显示**Using temporary**，表示的是需要使用临时表；**Using filesort**，表示的是需要执行排序操作。
   1. 对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL这时就会选择rowid排序。
2. **磁盘临时表**
   1. **tmp_table_size**这个配置**限制了内存临时表**的大小，**默认值是16M**。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。
### 18 为什么这些SQL语句逻辑相同，性能却差异巨大？

1. 案例一：**条件字段函数操作**
   1. 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。
2. 案例二：**隐式类型转换**
   1. 在MySQL中，字符串和数字做比较的话，是将字符串转换成数字。
3. 案例三：**隐式字符编码转换**
   1. 字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。
### 19 为什么我只查一行的语句，也执行这么慢？

1. 第一类：查询长时间不返回
   1. 等MDL锁
   1. 等flush
   1. 等行锁
2. 第二类：查询慢
   1. 见原文。带**lock in share mode**的SQL语句，是**当前读**，因此会直接读到1000001这个结果，所以速度很快；而select *fromt where id=1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次以后，才将1这个结果返回。
### 20 幻读是什么，幻读有什么问题？

1. 幻读是什么？
   1. 指的是**一个事务**在前后两次查询**同一个范围**的时候，后一次查询看到了前一次查询没有看到的**行**。
2. 对幻读的几个说明
   1. 可重复读隔离级别下，**普通的查询是快照读**，不会看到别的事务插入的数据。因此， **幻读在“当前读”下才会出现。 **
   1. 上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。** 幻读仅指“新插入的行”。**
   1. 当前读的规则，就是要能读到所有**已经提交**的记录的最新值。
3. 幻读有什么问题？
   1. 破坏了**行锁**的语义；
   1. **数据一致性**的问题；
4. 如何解决幻读？
   1. 产生幻读的原因是，行锁只能锁住**行**，但是新插入记录这个动作，要更新的是记录之间的“**间隙**”。
   1. 因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是**间隙锁(Gap Lock)**。
5. 间隙锁
   1. 间隙锁和行锁合称**next-key lock**，每个next-key lock是**前开后闭**区间。
   1. 我们把间隙锁记为**开**区间，把next-key lock记为前开后闭区间。
   1. 间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是**影响了并发度**的。并且会引入**死锁**问题。
   1. 间隙锁是在**可重复读**隔离级别下才会生效的。
6. **如果把隔离级别设置成读提交的话，就没有间隙锁了。**但同时，要解决可能出现的数据和日志不一致的情况，需要把binlog设置为row格式。
### 21 为什么我只改一行的语句，锁这么多？

1. 案例1：等值查询间隙锁
1. 案例2：非唯一索引等值锁
1. 案例3：主键索引范围锁
1. 案例4：非唯一索引范围锁
1. 案例5：唯一索引范围锁bug
1. 案例6：非唯一索引上存在“等值”的例子
1. 案例7：limit语句加锁
1. 案例8：一个死锁的例子
### 22 MySQL有哪些“饮鸩止渴”提高性能的方法？

- 短连接风暴
   - 第一种方法，先处理掉那些占着连接但是不工作的线程
   - 第二种方法，减少连接过程的消耗
- 慢查询性能问题
   - 索引没有设计好
   - SQL语句没写好
   - MySQL选错了索引
- QPS突增问题
### 23 MySQL是怎么保证数据不丢的？

1. **binlog的写入机制**
   1. 写入逻辑：事务执行过程中，先把日志写到**binlog cache**，事务提交的时候，再把binlog写到binlog磁盘文件中。
      1. 一个事务的binlog是不能拆开的。
      1. 系统给binlog cache分配了一片内存，**每个线程**一个，超过binlog_cache_size限制就暂存到磁盘。
      1. 事务提交的时候，执行器把binlog cache里的完整事务写到binlog中，并清空binlog cache。
   2. write和fsync
      1. write是指把日志写到文件系统的page cache
      1. fsync是指将数据持久化到磁盘
      1. write和fsync的时机由sync_binlog参数控制
         1. 为0，表示每次提交事务都只write，不fsync
         1. 为1，表示每次提交事务都fsync
         1. 为N，表示每次提交事务都write，累计N次后fsync
2. **redo log的写入机制**
   1. 事务在执行过程中，生成的redo log是要先写到**redo log buffer**的。
   1. redo log的写入策略由innodb_flush_log_at_trx_commit参数控制
      1. 为0，表示每次事务提交都只是把redo log留在redo log buffer中
      1. 为1，表示每次事务提交都将redo log持久化到磁盘
      1. 为2，表示每次事务提交都把redo log写到page cache
3. **双“1”配置**
   1. 指的就是将sync_binlog和innodb_flush_log_at_trx_commit都设置成“1”。意味着，一个事务完整提交前，需要等待**两次刷盘**，一次是redo log（prepare阶段），一次是binlog。
### 24 MySQL是怎么保证主备一致的？

1. **备库**设置成**只读 （readonly）**模式
   1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
   1. 防止切换逻辑有bug，比如切换过程中出现双写，造成主备不一致；
   1. 可以用readonly状态，来判断节点的角色。
   1. readonly设置对超级(super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限。
2. **binlog的三种格式对比**
   1. **statement**：记录的就是SQL语句的**原文**
      1. 问题：可能出现主备执行逻辑**不一致**的情况，同一句sql在两个库可能会出现执行逻辑不一样。
   2. **row：**row格式的binlog里没有了SQL语句的原文，而是替换成了**两个event：Table_map和Delete_rows**。
      1. Table_map event，用于说明接下来要操作的表是test库的表t; 
      1. Delete_rows event，用于定义删除的行为。
      1. 问题：解决了statement的不一致问题，但是**日志数据量会增大**
   3. **mixed**：mixed格式的意思是，MySQL自己会**判断**这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。
3. **循环复制问题**：通过以下三个准则解决
   1. 规定两个库的**server id必须不同**，如果相同，则它们之间不能设定为主备关系； 
   1. 一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog； 
   1. 每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。
### 25 MySQL是怎么保证高可用的？

1. **主备延迟**
   1. 网络正常情况下，主备延迟的主要来源是**备库接收完binlog和执行完这个事务之间的时间差**。
   1. 所以说，主备延迟最直接的表现是，**备库消费中转日志（relay log）的速度**，比主库生产binlog的速度要慢。
2. **主备延迟的来源**
   1. 首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。
   1. 追问1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？
      1. 这就是第二种常见的可能了，即**备库的压力大**。
         1. **一主多从**。除了备库外，可以多接几个从库，让这些从库来分担读的压力。 
         1. 通过**binlog输出到外部系统**，比如Hadoop这类系统，让外部系统提供统计类查询的能力。
   3. 追问2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？
      1. 这就是第三种可能了，即**大事务**。
      1. 另一种典型的大事务场景，就是**大表DDL**。
   4. 追问3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？
      1. 造成主备延迟还有一个大方向的原因，就是**备库的并行复制能力**。单线程复制，多线程复制。
3. 可靠性优先策略
3. 可用性优先策略
### 26 备库为什么会延迟好几个小时？

1. coordinator在分发的时候，需要满足以下两个基本条件
   1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个worker中。
   1. 同一个事务不能拆开，必须放到同一个worker中。
2. **并行复制策略**
   1. 按表分发
   1. 按行分发
   1. 。。。
### 27 主库出问题了，从库怎么办？

1. 基于位点的主备切换
1. GTID：GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成
   1. server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值； 
   1. gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。
3. 基于GTID的主备切换
   1. 在基于GTID的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。
4. GTID和在线DDL
### 28 读写分离有哪些坑？

1. “在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“**过期读**”。
1. **强制走主库方案**
   1. 实现方式：第三方插件（/*master*/、forceMaster()）；加事务。（底层是影响路由策略）
   1. 这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。
3. **sleep方案**
   1. 主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。
      1. 如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒； 
      1. 如果延迟超过1秒，还是会出现过期读。
4. **判断主备无延迟方案**
   1. 第一种方法是，每次从库执行查询请求前，先判断**seconds_behind_master**是否已经等于0。如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。
   1. 第二种方法，对比**位点**确保主备无延迟
   1. 第三种方法，对比**GTID集合**确保主备无延迟
5. **配合semi-sync方案**
   1. 如果启用了semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。
      1. 事务提交的时候，主库把binlog发给从库
      1. 从库收到binlog后，发回主库一个ack
      1. 主库收到ack以后，才能返回客户端“事务完成”
   2. 存在两个问题
      1. **一主多从**的时候，在某些从库执行查询请求会存在过期读的现象； 
      1. 在业务高峰期持续延迟的情况下，可能出现**过度等待**的问题。
6. **等主库位点方案**
   1. select master_pos_wait(file, pos[timeout])
      1. 在从库上执行
      1. 参数file和pos指的是主库上的文件名和位置
      1. timeout可选，表示最多等待n秒
   2. **退化机制**。如果超时时间内未返回大于等于0的数，就走主库。
7. **等GTID方案**
   1. 主库事务完成后，返回给客户端这个事务的gtid
   1. select wait_for_executed_gtid_set(gtid_set, 1)
      1. 等待，直到这个库执行的事务中包含传入的gtid_set，返回0
      1. 超时返回1
### 29 如何判断一个数据库是不是出问题了？

1. select 1判断
1. 查表判断
1. 更新判断
1. 内部统计
### 30 答疑文章（二）：用动态的观点看加锁

1. 两个“原则”、两 个“优化”和一个“bug”
   1. 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。 
   1. 原则2：查找过程中访问到的对象（索引）才会加锁。 
   1. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
   1. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。 
   1. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。
### 31 误删数据后除了跑路，还能怎么办？

1. 使用delete语句误删数据行；
1. 使用drop table或者truncate table语句误删数据表；
1. 使用drop database语句误删数据库；
1. 使用rm命令误删整个MySQL实例。
### 32 为什么还有kill不掉的语句？
### 33 我查这么多数据，会不会把数据库内存打爆？

1. **全表扫描**对server层的影响
   1. MySQL是“**边读边发**”的
   1. 查询的结果是**分段**发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。
2. **全表扫描**对InnoDB的影响
   1. 内存的数据页是在Buffer Pool中管理的，在WAL里Buffer Pool 起到了**加速更新**的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是**加速查询**。
   1. **InnoDB对LRU算法做了改进**
      1. 在InnoDB实现上，按照**5:3**的比例把整个LRU链表分成了**young**区域和**old**区域。
      1. 扫描过程中，需要**新**插入的数据页，都被放到**old**区域;
      1. 一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒，因此还是会被保留在old区域；
      1. 再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是young区域），很快就会被淘汰出去。
### 34 到底可不可以使用join？

1. **Index Nested-Loop Join**
   1. 这个过程是先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上**被驱动表**的**索引**， 所以我们称之为“IndexNested-Loop Join”，简称NLJ。
2. **Simple Nested-Loop Join**
   1. 被驱动表使用不了索引
   1. MySQL没有使用这种算法
3. **Block Nested-Loop Join**
   1. 被驱动表使用不了索引
   1. 先把驱动表数据读入内存join buffer，再把被驱动表数据读出来在内存里做一次判断。
   1. join_buffer的大小是由参数join_buffer_size设定的，默认值是256k。如果放不下表t1的所有数 据话，策略很简单，就是分段放。
   1. 基于内存操作，性能更好。
   1. “Block”的由来，表示“分块去join”。
4. **能不能使用join语句？**
   1. 如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是
没问题的；
   1. 如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这
样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。
   1. 所以你在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“Block
Nested Loop”字样。
5. 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。
### 35 join语句怎么优化？

1. **Multi-Range Read优化**
   1. 这个优化的主要目的是尽量使用**顺序读盘**。回表肯定是 一行行搜索主键索引的，**因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键 的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。**
   1. 这，就是MRR优化的设计思路。此时，语句的执行流程变成了这样：
      1. 根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中; 
      1. 将read_rnd_buffer中的id进行递增排序； 
      1. 排序后的id数组，依次到主键id索引中查记录，并作为结果返回。
   3. 如果你想要稳定地使用MRR优化的话，需要设置set optimizer_switch="mrr_cost_based=off"
   3. MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这 是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能 体现出“顺序性”的优势。
2. **Batched Key Access**
   1. 如果NLJ算法执行的逻辑是：从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。也就是 说，对于表t2来说，每次都是匹配一个值。这时，MRR的优势就用不上了。
   1. 那怎么才能一次性地多传些值给表t2呢？方法就是，从表t1里一次性地多拿些行出来，一起传给表t2。 既然如此，我们就把表t1的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是join_buffer。
   1. set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on'。其中，前两个参数的作用是要启用MRR。这么做的原因是，BKA算法的优化要依赖于MRR。
3. **BNL算法的性能问题**
   1. 如果这个被驱动表是一个大的冷数据表，除了会导致IO压力大以外，还会对系统有什么影响呢？
      1. 但是，如果一个使用BNL算法的join语句，多次扫描一个冷表，而且这个语句执行时间超过1秒， 就会在再次扫描冷表的时候，把冷表的数据页移到LRU链表头部。
      1. 大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了。但是， 对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。
4. **BNL转BKA**
   1. 一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成BKA算法了。 
   1. 但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。
      1. 可以考虑使用临时表，在临时表上加索引
   3. 总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让join语句能够用上被驱动表上的索引，来触发BKA算法，提升查询性能。
5. **扩展-hash join**
   1. 如果join_buffer里面 维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查 找。
   1. MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join
   1. 可以业务代码里实现hash join
### 36 为什么临时表可以重名？
### 37 什么时候会使用内部临时表？

1. union 执行流程
   1. 这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键id的唯一性约束，实现了union的语义。
   1. 如果把上面这个语句中的union改成union all的话，就没有了“**去重**”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。
2. group by 执行流程
   1. select id%10 as m, count(*) as c from t1 group by m;
   1. 创建**内存临时表**，表里有两个字段m和c，主键是m；
   1. 扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；如果临时表中没有主键为x的行，就插入一个记录(x,1);如果表中有主键为x的行，就将x这一行的c值加1；
   1. 遍历完成后，再根据字段m做排序，得到结果集返回给客户端。
3. group by 优化方法 --索引
   1. 在MySQL 5.7版本支持了**generated column**机制，用来实现列数据的关联更新。
```sql
alter table t1 add column z int generated always as(id % 100), add index(z);
```

5. group by优化方法 --直接排序
   1. 在group by语句中加入**SQL_BIG_RESULT**这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。
6. MySQL什么时候会使用内部临时表？
   1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
   1. join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；
   1. 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。
7. 指导原则：
   1. 如果对group by语句的结果没有排序要求，要在语句后面加 order bynull； 
   1. 尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary和 Using filesort； 
   1. 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size参数，来避免用到磁盘临时表； 
   1. 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法 得到group by的结果。
### 38 都说InnoDB好那还要不要使用Memory引擎？
### 39 自增主键为什么不是连续的？

1. 自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。
1. 自增值保存在哪儿？
   1. MyISAM引擎的自增值保存在数据文件中。
   1. InnoDB引擎
      1. 5.7及之前的版本，自增值保存在**内存**里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的 自增值。
      1. 8.0版本，将自增值的变更记录在了**redo log**中，重启的时候依靠redo log恢复 重启之前的值。
3. 自增值修改机制
   1. 新的自增值生成算法是：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于X的值，作为新的自增值。
   1. 双M的主备结构里要求双写的时候，我 们就可能会设置成auto_increment_increment=2，让一个库的自增id都是奇数，另一个库的自增id都是偶数，避免两个库生成的主键发生冲突。
4. 自增值的修改时机
   1. **唯一键冲突**是导致自增主键id不连续
   1. **回滚**也会产生类似的现象
   1. 对于批量插入数据的语句，MySQL有一个**批量申请自增id**的策略，申请了没用也会导致id不连续
### 45 自增id用完怎么办？

1. 表的**自增id**达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报**主键冲突**的错误。
1. **row_id**达到上限后，则会**归0**再重新递增，如果出现相同的row_id，后写的数据会**覆盖**之前的数据。
1. **Xid**只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
1. InnoDB的**max_trx_id **递增值每次MySQL重启都会被保存起来，所以我们文章中提到的**脏读**的例子就是一个必现的bug，好在留给我们的时间还很充裕。
1. **thread_id**是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了。
